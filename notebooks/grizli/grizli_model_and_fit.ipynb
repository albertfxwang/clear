{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows how to use Grizli to\n",
    "\n",
    "model contamination + continuum + emission for G102/G141 observations of a single object in the CLEAR GS1 field. The final products are 1D and 2D spectra and line maps.\n",
    "\n",
    "These series of notebooks draw heavily from Gabe Brammer's existing grizli notebooks, which are available at https://github.com/gbrammer/grizli/tree/master/examples, but with examples specific for the CLEAR survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import drizzlepac\n",
    "import grizli\n",
    "import glob\n",
    "from grizli import utils\n",
    "import importlib\n",
    "from grizli.prep import process_direct_grism_visit\n",
    "from hsaquery import query, overlaps\n",
    "from grizli.pipeline import auto_script\n",
    "from grizli.multifit import GroupFLT, MultiBeam, get_redshift_fit_defaults\n",
    "import os\n",
    "from grizli.pipeline import photoz\n",
    "from astropy.table import Table\n",
    "import eazy\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***The following paths need to be changed for your filesystem.***\n",
    "\n",
    "### [HOME_PATH] is where the raw data, reduced data, and `Grizli` outputs will be stored.\n",
    "\n",
    "### [PATH_TO_CATS] is where the catalogs are stored and must include the following:\n",
    "        ###     reference mosaic image (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sci.fits)\n",
    "        ###     segmentation map       (e.g., Goods_S_plus_seg.fits)\n",
    "        ###     source catalog         (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat)\n",
    "        ###     radec_catalog          (e.g., goodsS_radec.cat)\n",
    "        ###     3DHST Eazy Catalogs    (e.g., goodss_3dhst.v4.1.cats/*)\n",
    "        \n",
    "the [PATH_TO_CATS] files are available on the team archive: https://archive.stsci.edu/pub/clear_team/INCOMING/for_hackday/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field           = 'GS1'\n",
    "ref_filter      = 'F105W'\n",
    "HOME_PATH       = '/Users/rsimons/Desktop/clear/for_hackday/%s'%field\n",
    "PATH_TO_SCRIPTS = '/Users/rsimons/Desktop/git/clear_local/example_notebooks'\n",
    "PATH_TO_CATS    = '/Users/rsimons/Desktop/clear/Catalogs'\n",
    "PATH_TO_RAW     = glob.glob(HOME_PATH + '/*/RAW')[0]\n",
    "PATH_TO_PREP    = glob.glob(HOME_PATH + '/*/PREP')[0]\n",
    "\n",
    "\n",
    "class Pointing():\n",
    "    \"\"\" Generalization of GN1, GS1, ERSPRIME, etc\n",
    "\n",
    "    To change field-dependent catalog, seg map, ref image, and padding\n",
    "    only need to change them here.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, field, ref_filter):\n",
    "        if 'N' in field.upper():\n",
    "            self.pad = 500 # really only necessary for GDN\n",
    "            self.radec_catalog = PATH_TO_CATS + '/goodsN_radec.cat'\n",
    "            self.seg_map =  PATH_TO_CATS + '/Goods_N_plus_seg.fits'\n",
    "            self.catalog =  PATH_TO_CATS + '/goodsn-F105W-astrodrizzle-v4.4_drz_sub_plus.cat'\n",
    "            self.ref_image =  PATH_TO_CATS + '/goodsn-F105W-astrodrizzle-v4.4_drz_sci.fits'\n",
    "            \n",
    "            self.tempfilt, self.coeffs, self.temp_sed, self.pz = readEazyBinary(MAIN_OUTPUT_FILE='goodsn_3dhst.v4.1', OUTPUT_DIRECTORY=PATH_TO_CATS, CACHE_FILE='Same')\n",
    "            self.params = {}\n",
    "            self.params['CATALOG_FILE'] = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Catalog/{0}_3dhst.{1}.cat'.format('goodsn', 'v4.1')\n",
    "            self.params['Z_STEP'] = 0.002\n",
    "            self.params['Z_MAX'] = 4\n",
    "            self.params['MAIN_OUTPUT_FILE'] = '{0}_3dhst.{1}.eazypy'.format('goodsn', 'v4.1')\n",
    "            self.params['PRIOR_FILTER'] = 205\n",
    "            self.params['MW_EBV'] = {'aegis':0.0066, 'cosmos':0.0148, 'goodss':0.0069, \n",
    "                                    'uds':0.0195, 'goodsn':0.0103}['goodsn']\n",
    "            self.params['TEMPLATES_FILE'] = 'templates/fsps_full/tweak_fsps_QSF_12_v3.param'\n",
    "            self.translate_file = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Eazy/{0}_3dhst.{1}.translate'.format('goodsn', 'v4.1')\n",
    "\n",
    "        elif 'S' in field.upper():\n",
    "            self.pad = 200 # grizli default\n",
    "            self.radec_catalog =  PATH_TO_CATS + '/goodsS_radec.cat'\n",
    "            self.seg_map =  PATH_TO_CATS + '/Goods_S_plus_seg.fits'\n",
    "            self.catalog =  PATH_TO_CATS + '/goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat'\n",
    "            self.ref_image =  PATH_TO_CATS + '/goodss-F105W-astrodrizzle-v4.3_drz_sci.fits'\n",
    "\n",
    "\n",
    "            self.tempfilt, self.coeffs, self.temp_sed, self.pz = readEazyBinary(MAIN_OUTPUT_FILE='goodss_3dhst.v4.1', OUTPUT_DIRECTORY=PATH_TO_CATS, CACHE_FILE='Same')\n",
    "            self.params = {}\n",
    "            self.params['CATALOG_FILE'] = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Catalog/{0}_3dhst.{1}.cat'.format('goodss', 'v4.1')\n",
    "            self.params['Z_STEP'] = 0.002\n",
    "            self.params['Z_MAX'] = 4\n",
    "            self.params['MAIN_OUTPUT_FILE'] = '{0}_3dhst.{1}.eazypy'.format('goodss', 'v4.1')\n",
    "            self.params['PRIOR_FILTER'] = 205\n",
    "            self.params['MW_EBV'] = {'aegis':0.0066, 'cosmos':0.0148, 'goodss':0.0069, \n",
    "                                    'uds':0.0195, 'goodsn':0.0103}['goodss']\n",
    "            self.params['TEMPLATES_FILE'] = 'templates/fsps_full/tweak_fsps_QSF_12_v3.param'\n",
    "            self.translate_file = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Eazy/{0}_3dhst.{1}.translate'.format('goodss', 'v4.1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def readEazyBinary(MAIN_OUTPUT_FILE='photz', OUTPUT_DIRECTORY='./OUTPUT', CACHE_FILE='Same'):\n",
    "\n",
    "    \"\"\"\n",
    "    Author: Gabe Brammer\n",
    "    This function has been clipped from eazyPy.py in the threedhst git respository\n",
    "    https://github.com/gbrammer/threedhst/tree/master/threedhst\n",
    "\n",
    "    tempfilt, coeffs, temp_sed, pz = readEazyBinary(MAIN_OUTPUT_FILE='photz', \\\n",
    "                                                OUTPUT_DIRECTORY='./OUTPUT', \\\n",
    "                                                CACHE_FILE = 'Same')\n",
    "\n",
    "    Read Eazy BINARY_OUTPUTS files into structure data.\n",
    "    \n",
    "    If the BINARY_OUTPUTS files are not in './OUTPUT', provide either a relative or absolute path\n",
    "    in the OUTPUT_DIRECTORY keyword.\n",
    "    \n",
    "    By default assumes that CACHE_FILE is MAIN_OUTPUT_FILE+'.tempfilt'.\n",
    "    Specify the full filename if otherwise. \n",
    "    \"\"\"\n",
    "    \n",
    "    #root='COSMOS/OUTPUT/cat3.4_default_lines_zp33sspNoU'\n",
    "    \n",
    "    root = OUTPUT_DIRECTORY+'/'+MAIN_OUTPUT_FILE\n",
    "    \n",
    "    ###### .tempfilt\n",
    "    if CACHE_FILE == 'Same':\n",
    "        CACHE_FILE = root+'.tempfilt'\n",
    "    \n",
    "    if os.path.exists(CACHE_FILE) is False:\n",
    "        print(('File, %s, not found.' %(CACHE_FILE)))\n",
    "        return -1,-1,-1,-1\n",
    "    \n",
    "    f = open(CACHE_FILE,'rb')\n",
    "    \n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=4)\n",
    "    NFILT=s[0]\n",
    "    NTEMP=s[1]\n",
    "    NZ=s[2]\n",
    "    NOBJ=s[3]\n",
    "    tempfilt = np.fromfile(file=f,dtype=np.double,count=NFILT*NTEMP*NZ).reshape((NZ,NTEMP,NFILT)).transpose()\n",
    "    lc = np.fromfile(file=f,dtype=np.double,count=NFILT)\n",
    "    zgrid = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    fnu = np.fromfile(file=f,dtype=np.double,count=NFILT*NOBJ).reshape((NOBJ,NFILT)).transpose()\n",
    "    efnu = np.fromfile(file=f,dtype=np.double,count=NFILT*NOBJ).reshape((NOBJ,NFILT)).transpose()\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    tempfilt  = {'NFILT':NFILT,'NTEMP':NTEMP,'NZ':NZ,'NOBJ':NOBJ,\\\n",
    "                 'tempfilt':tempfilt,'lc':lc,'zgrid':zgrid,'fnu':fnu,'efnu':efnu}\n",
    "    \n",
    "    ###### .coeff\n",
    "    f = open(root+'.coeff','rb')\n",
    "    \n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=4)\n",
    "    NFILT=s[0]\n",
    "    NTEMP=s[1]\n",
    "    NZ=s[2]\n",
    "    NOBJ=s[3]\n",
    "    coeffs = np.fromfile(file=f,dtype=np.double,count=NTEMP*NOBJ).reshape((NOBJ,NTEMP)).transpose()\n",
    "    izbest = np.fromfile(file=f,dtype=np.int32,count=NOBJ)\n",
    "    tnorm = np.fromfile(file=f,dtype=np.double,count=NTEMP)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    coeffs = {'NFILT':NFILT,'NTEMP':NTEMP,'NZ':NZ,'NOBJ':NOBJ,\\\n",
    "              'coeffs':coeffs,'izbest':izbest,'tnorm':tnorm}\n",
    "              \n",
    "    ###### .temp_sed\n",
    "    f = open(root+'.temp_sed','rb')\n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=3)\n",
    "    NTEMP=s[0]\n",
    "    NTEMPL=s[1]\n",
    "    NZ=s[2]\n",
    "    templam = np.fromfile(file=f,dtype=np.double,count=NTEMPL)\n",
    "    temp_seds = np.fromfile(file=f,dtype=np.double,count=NTEMPL*NTEMP).reshape((NTEMP,NTEMPL)).transpose()\n",
    "    da = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    db = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    temp_sed = {'NTEMP':NTEMP,'NTEMPL':NTEMPL,'NZ':NZ,\\\n",
    "              'templam':templam,'temp_seds':temp_seds,'da':da,'db':db}\n",
    "              \n",
    "    ###### .pz\n",
    "    if os.path.exists(root+'.pz'):\n",
    "        f = open(root+'.pz','rb')\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=2)\n",
    "        NZ=s[0]\n",
    "        NOBJ=s[1]\n",
    "        chi2fit = np.fromfile(file=f,dtype=np.double,count=NZ*NOBJ).reshape((NOBJ,NZ)).transpose()\n",
    "\n",
    "        ### This will break if APPLY_PRIOR No\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=1)\n",
    "        \n",
    "        if len(s) > 0:\n",
    "            NK = s[0]\n",
    "            kbins = np.fromfile(file=f,dtype=np.double,count=NK)\n",
    "            priorzk = np.fromfile(file=f, dtype=np.double, count=NZ*NK).reshape((NK,NZ)).transpose()\n",
    "            kidx = np.fromfile(file=f,dtype=np.int32,count=NOBJ)\n",
    "            pz = {'NZ':NZ,'NOBJ':NOBJ,'NK':NK, 'chi2fit':chi2fit, 'kbins':kbins, 'priorzk':priorzk,'kidx':kidx}\n",
    "        else:\n",
    "            pz = None\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    else:\n",
    "        pz = None\n",
    "    \n",
    "    if False:\n",
    "        f = open(root+'.zbin','rb')\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=1)\n",
    "        NOBJ=s[0]\n",
    "        z_a = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_p = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_m1 = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_m2 = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_peak = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        f.close()\n",
    "        \n",
    "    ###### Done.    \n",
    "    return tempfilt, coeffs, temp_sed, pz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_TO_PREP)\n",
    "files = glob.glob('%s/*flt.fits'%PATH_TO_RAW)\n",
    "info = grizli.utils.get_flt_info(files)\n",
    "visits, filters = grizli.utils.parse_flt_files(info=info, uniquename=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = np.array([visit['product'] for visit in visits])\n",
    "filter_names = np.array([visit['product'].split('-')[-1] for visit in visits])\n",
    "basenames = np.array([visit['product'].split('.')[0]+'.0' for visit in visits])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grism_files = []\n",
    "all_direct_files = []\n",
    "\n",
    "ref_filter_1 = 'F105W' \n",
    "ref_filter_2 = 'F140W'\n",
    "\n",
    "ref_grism_1 = 'G102'\n",
    "ref_grism_2 = 'G141'\n",
    "\n",
    "for v, visit in enumerate(visits):\n",
    "    product = product_names[v]\n",
    "    basename = basenames[v]\n",
    "    filt1 = filter_names[v]\n",
    "    if (ref_filter_1.lower() in filt1) or (ref_filter_2.lower() in filt1):\n",
    "        all_direct_files.extend(visit['files'])\n",
    "        grism_index_1 = np.where((basenames == basename) & (filter_names == ref_grism_1.lower()))[0]\n",
    "        grism_index_2 = np.where((basenames == basename) & (filter_names == ref_grism_2.lower()))[0]\n",
    "        if len(grism_index_1) > 0:\n",
    "            all_grism_files.extend(visits[grism_index_1[0]]['files'])\n",
    "        if len(grism_index_2) > 0:\n",
    "            all_grism_files.extend(visits[grism_index_2[0]]['files'])\n",
    "        \n",
    "print ('Number of direct files:', len(all_direct_files))\n",
    "print ('Number of grism files:', len(all_grism_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pointing(field = field, ref_filter = ref_filter_1)\n",
    "print('Initializing (or loading pre-existing) contamination models...')\n",
    "\n",
    "grp = GroupFLT(grism_files=all_grism_files, \n",
    "               direct_files=[], \n",
    "               ref_file = p.ref_image,\n",
    "               seg_file = p.seg_map,\n",
    "               catalog  = p.catalog,\n",
    "               pad=p.pad,\n",
    "               cpu_count=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contamination models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing first-pass contamination models...')\n",
    "grp.compute_full_model(mag_limit = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=[30,10])\n",
    "axes[0].imshow(grp.FLTs[0].grism['SCI'], vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "axes[1].imshow(grp.FLTs[0].model, vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "axes[2].imshow(grp.FLTs[0].grism['SCI'] - grp.FLTs[0].model, vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(200,1200) \n",
    "    ax.set_ylim(200,1200)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Re-computing continuum models, but with higher-order polynomials..')\n",
    "grp.refine_list(poly_order=2, mag_limits=[16, 24], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.clf()\n",
    "fig, axes = plt.subplots(1,3, figsize=[30,10])\n",
    "axes[0].imshow(grp.FLTs[0].grism['SCI'], vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "axes[1].imshow(grp.FLTs[0].model, vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "axes[2].imshow(grp.FLTs[0].grism['SCI'] - grp.FLTs[0].model, vmin=-0.02, vmax=0.2, cmap='cubehelix_r',interpolation='Nearest', origin='lower')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(200,1200) \n",
    "    ax.set_ylim(200,1200)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving contamination models')\n",
    "grp.save_full_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eazy.symlink_eazy_inputs(path=os.path.dirname(eazy.__file__)+'/data', \n",
    "                         path_is_env=False)\n",
    "templ0 = grizli.utils.load_templates(fwhm=1200, line_complexes=True, stars=False, \n",
    "                                     full_line_list=None,  continuum_list=None, \n",
    "                                     fsps_templates=True)\n",
    "\n",
    "# Load individual line templates for fitting the line fluxes\n",
    "templ1 = grizli.utils.load_templates(fwhm=1200, line_complexes=False, stars=False, \n",
    "                                     full_line_list=None, continuum_list=None, \n",
    "                                     fsps_templates=True)\n",
    "\n",
    "pline = {'kernel': 'point', 'pixfrac': 0.2, 'pixscale': 0.1, 'size': 8, 'wcs': None}\n",
    "ez = eazy.photoz.PhotoZ(param_file=None, translate_file=p.translate_file, \n",
    "                        zeropoint_file=None, params=p.params, \n",
    "                        load_prior=True, load_products=False)\n",
    "\n",
    "ep = photoz.EazyPhot(ez, grizli_templates=templ0, zgrid=ez.zgrid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Fitting a single object, ID = 43404 </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and write-out the 2D spectrum of a single object. These cutouts are referred to as \"beams\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_fit = 43403\n",
    "beams = grp.get_beams(id_fit, size=80)\n",
    "print(\"beams: \", beams)\n",
    "mb = grizli.multifit.MultiBeam(beams, fcontam=1.0, group_name=field)\n",
    "mb.write_master_fits()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit polynomial model for initial continuum subtraction\n",
    "wave = np.linspace(2000,2.5e4,100)\n",
    "poly_templates = grizli.utils.polynomial_templates(\n",
    "    wave=wave, \n",
    "    order=7,\n",
    "    line=False)\n",
    "\n",
    "pfit = mb.template_at_z(\n",
    "    z=0, \n",
    "    templates=poly_templates, \n",
    "    fit_background=True, \n",
    "    fitter='lstsq', \n",
    "    fwhm=1400, \n",
    "    get_uncertainties=2)\n",
    "\n",
    "\n",
    "hdu, fig = mb.drizzle_grisms_and_PAs(\n",
    "    size=32, \n",
    "    fcontam=0.2, \n",
    "    flambda=False, \n",
    "    scale=1, \n",
    "    pixfrac=0.5, \n",
    "    kernel='point', \n",
    "    make_figure=True, \n",
    "    usewcs=False, \n",
    "    zfit=pfit,\n",
    "    diff=True)\n",
    "# Save drizzled (\"stacked\") 2D trace as PNG and FITS\n",
    "fig.savefig('{0}_{1:05d}.stack.png'.format(field, id_fit))\n",
    "hdu.writeto('{0}_{1:05d}.stack.fits'.format(field, id_fit), clobber=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = utils.GTable()\n",
    "tab['ra'] = [mb.ra]\n",
    "tab['dec'] = [mb.dec]\n",
    "tab['id'] = id_fit\n",
    "phot, ii, dd = ep.get_phot_dict(tab['ra'][0], tab['dec'][0])\n",
    "out = grizli.fitting.run_all(\n",
    "    id_fit, \n",
    "    t0=templ0, \n",
    "    t1=templ1, \n",
    "    fwhm=1200, \n",
    "    zr=[0.0, 3.5], \n",
    "    dz=[0.004, 0.0005], \n",
    "    fitter='nnls',\n",
    "    group_name=field,\n",
    "    fit_stacks=True, \n",
    "    prior=None, \n",
    "    fcontam=0.,\n",
    "    pline=pline, \n",
    "    mask_sn_limit=7, \n",
    "    fit_only_beams=False,\n",
    "    fit_beams=True, \n",
    "    root=field,\n",
    "    fit_trace_shift=False, \n",
    "    phot=phot, \n",
    "    verbose=True, \n",
    "    scale_photometry= 0, \n",
    "    show_beams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb, st, fit, tfit, line_hdu = out\n",
    "fit_hdu = fits.open('{0}_{1:05d}.full.fits'.format(field, id_fit)) \n",
    "\n",
    "fit_hdu.info()\n",
    "# same as the fit table above, redshift fit to the stacked spectra\n",
    "fit_stack = Table(fit_hdu['ZFIT_STACK'].data) \n",
    "\n",
    "\n",
    "# zoom in around the initial best-guess with the individual \"beam\" spectra\n",
    "fit_beam = Table(fit_hdu['ZFIT_BEAM'].data)   \n",
    "\n",
    "templ = Table(fit_hdu['TEMPL'].data)\n",
    "print('{0} has lines [{1}]'.format(fit_hdu.filename(), fit_hdu[0].header['HASLINES']))\n",
    "\n",
    "# Helper script for plotting them, not generated automatically\n",
    "fig = grizli.fitting.show_drizzled_lines(fit_hdu, size_arcsec=1.6, cmap='plasma_r')\n",
    "fig.savefig('{0}_{1:05d}.line.png'.format(field, id_fit))\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Grizli products</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack of Grism orients\n",
    "\n",
    "left columns:  G102\n",
    "\n",
    "right columns: G141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = PATH_TO_PREP + '/GS1_43403.stack.png', width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SED fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = PATH_TO_PREP + '/GS1_43403.sed.png', width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = PATH_TO_PREP + '/GS1_43403.full.png', width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission line maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = PATH_TO_PREP + '/GS1_43403.line.png', width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Batch-mode fitting</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper for fitting routines above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grizli_fit(grp, id_fit, field = '', ref_filter = 'F105W', use_pz_prior = True, use_phot = True, scale_phot = True, templ0 = None, templ1 = None, ep = None, pline = None):\n",
    "    beams = grp.get_beams(id_fit, size=80)\n",
    "    if beams != []:\n",
    "        print(\"beams: \", beams)\n",
    "        mb = grizli.multifit.MultiBeam(beams, fcontam=1.0, group_name=field)\n",
    "        mb.write_master_fits()\n",
    "\n",
    "        # Fit polynomial model for initial continuum subtraction\n",
    "        wave = np.linspace(2000,2.5e4,100)\n",
    "        poly_templates = grizli.utils.polynomial_templates(\n",
    "            wave=wave, \n",
    "            order=7,\n",
    "            line=False)\n",
    "\n",
    "        pfit = mb.template_at_z(\n",
    "            z=0, \n",
    "            templates=poly_templates, \n",
    "            fit_background=True, \n",
    "            fitter='lstsq', \n",
    "            fwhm=1400, \n",
    "            get_uncertainties=2)\n",
    "\n",
    "\n",
    "        if pfit != None:\n",
    "        # Drizzle grisms / PAs\n",
    "            hdu, fig = mb.drizzle_grisms_and_PAs(\n",
    "                size=32, \n",
    "                fcontam=0.2, \n",
    "                flambda=False, \n",
    "                scale=1, \n",
    "                pixfrac=0.5, \n",
    "                kernel='point', \n",
    "                make_figure=True, \n",
    "                usewcs=False, \n",
    "                zfit=pfit,\n",
    "                diff=True)\n",
    "            # Save drizzled (\"stacked\") 2D trace as PNG and FITS\n",
    "            fig.savefig('{0}_{1:05d}.stack.png'.format(field, id_fit))\n",
    "            hdu.writeto('{0}_{1:05d}.stack.fits'.format(field, id_fit), clobber=True)\n",
    "\n",
    "\n",
    "\n",
    "            if use_pz_prior:\n",
    "                #use redshift prior from z_phot\n",
    "                prior = np.zeros((2, len(p.tempfilt['zgrid'])))\n",
    "                prior[0] = p.tempfilt['zgrid']\n",
    "                prior[1] = p.pz['chi2fit'][:,id]\n",
    "            else:\n",
    "                prior = None \n",
    "            order = 0\n",
    "\n",
    "\n",
    "\n",
    "            tab = utils.GTable()\n",
    "            tab['ra'] = [mb.ra]\n",
    "            tab['dec'] = [mb.dec]\n",
    "\n",
    "            tab['id'] = id_fit\n",
    "            phot, ii, dd = ep.get_phot_dict(tab['ra'][0], tab['dec'][0])\n",
    "            out = grizli.fitting.run_all(\n",
    "                id_fit, \n",
    "                t0=templ0, \n",
    "                t1=templ1, \n",
    "                fwhm=1200, \n",
    "                zr=[0.0, 3.5], \n",
    "                dz=[0.004, 0.0005], \n",
    "                fitter='nnls',\n",
    "                group_name=field,\n",
    "                fit_stacks=True, \n",
    "                prior=None, \n",
    "                fcontam=0.,\n",
    "                pline=pline, \n",
    "                mask_sn_limit=7, \n",
    "                fit_only_beams=False,\n",
    "                fit_beams=True, \n",
    "                root=field,\n",
    "                fit_trace_shift=False, \n",
    "                phot=phot, \n",
    "                verbose=True, \n",
    "                scale_photometry=order, \n",
    "                show_beams=True)\n",
    "            mb, st, fit, tfit, line_hdu = out\n",
    "            fit_hdu = fits.open('{0}_{1:05d}.full.fits'.format(field, id_fit)) \n",
    "\n",
    "            fit_hdu.info()\n",
    "            # same as the fit table above, redshift fit to the stacked spectra\n",
    "            fit_stack = Table(fit_hdu['ZFIT_STACK'].data) \n",
    "\n",
    "\n",
    "            # zoom in around the initial best-guess with the individual \"beam\" spectra\n",
    "            fit_beam = Table(fit_hdu['ZFIT_BEAM'].data)   \n",
    "\n",
    "            templ = Table(fit_hdu['TEMPL'].data)\n",
    "            print('{0} has lines [{1}]'.format(fit_hdu.filename(), fit_hdu[0].header['HASLINES']))\n",
    "\n",
    "            # Helper script for plotting them, not generated automatically\n",
    "            fig = grizli.fitting.show_drizzled_lines(fit_hdu, size_arcsec=1.6, cmap='plasma_r')\n",
    "            fig.savefig('{0}_{1:05d}.line.png'.format(field, id_fit))\n",
    "            plt.close('all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting every object in the field with jh mag < 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit all objects with MAG_AUTO < 22\n",
    "if False:\n",
    "    good = np.where(np.array(grp.catalog['MAG_AUTO']) < 22)[0]\n",
    "    for g in good:\n",
    "        id_fit = np.array(grp.catalog['NUMBER'])[g]\n",
    "        mag_fit = grp.catalog['MAG_AUTO'][g]\n",
    "        grizli_fit(grp, id_fit = id_fit, field = field,\n",
    "                   use_pz_prior = False, use_phot = True, scale_phot = True,\n",
    "                   templ0 = templ0, templ1 = templ1, ep = ep, pline = pline,)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
