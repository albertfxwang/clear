{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## This notebook shows how to use Grizli to\n",
    "\n",
    "Retrieve and reduce raw CLEAR G102/F105W and 3D-HST G141/F140W observations for a specific CLEAR pointing (GS1).\n",
    "        \n",
    "** more comments inbound\n",
    "\n",
    "These series of notebooks draw heavily from Gabe Brammer's existing grizli notebooks, which are available at https://github.com/gbrammer/grizli/tree/master/examples, but with specific focus for the CLEAR survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grizli\n",
    "\n",
    "try: \n",
    "    from mastquery import query, overlaps\n",
    "    use_mquery = True\n",
    "except: \n",
    "    from hsaquery import query, overlaps\n",
    "    use_mquery = False\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from grizli.pipeline import auto_script\n",
    "import glob\n",
    "from glob import glob\n",
    "import astropy\n",
    "from grizli.prep import process_direct_grism_visit\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The paths defined below need to be changed to your own directories.\n",
    "### the PATH_TO_CATS directory should include the following:\n",
    "        ###     reference mosaic image (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sci.fits)\n",
    "        ###     segmentation map       (e.g., Goods_S_plus_seg.fits)\n",
    "        ###     source catalog         (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat)\n",
    "        ###     radec_catalog          (e.g., goodsS_radec.cat)\n",
    "        ###     3DHST Eazy Catalogs    (e.g., goodss_3dhst.v4.1.cats/*)\n",
    "### these are all available on the team archive: https://archive.stsci.edu/pub/clear_team/INCOMING/for_hackday/\n",
    "### the HOME_PATH directory is where the raw data, reduced data, and grizli outputs will be stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field           = 'GS1'\n",
    "ref_filter      = 'F105W'\n",
    "\n",
    "HOME_PATH       = '/Users/rsimons/Desktop/clear/for_hackday/%s'%field\n",
    "PATH_TO_CATS    = '/Users/rsimons/Desktop/clear/Catalogs'\n",
    "\n",
    "if not os.path.isdir(HOME_PATH): os.system('mkdir %s'%HOME_PATH)\n",
    "if not os.path.isdir(HOME_PATH + '/query_results'): os.system('mkdir %s/query_results'%HOME_PATH)\n",
    "\n",
    "os.chdir(HOME_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an initial query for all raw G102 data in the ESA archive with a target name that includes the phrase 'GS1' and a proposal ID of 14227 (i.e., GS1 pointing of CLEAR). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = query.run_query(box = None, proposal_id = [14227], instruments=['WFC3/IR', 'ACS/WFC'], \n",
    "                         filters = ['G102'], target_name = 'GS1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, find all overlapping G102 and G141 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all overlapping G102 and G141 observations in the archive\n",
    "tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, \n",
    "                              filters=['G102', 'G141'], \n",
    "                              instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], close=False)\n",
    "\n",
    "footprint_fits_file = glob('*footprint.fits')[0]\n",
    "jtargname = footprint_fits_file.strip('_footprint.fits')\n",
    "\n",
    "fp_fits = fits.open(footprint_fits_file)\n",
    "\n",
    "overlapping_target_names = set(fp_fits[1].data['target'])\n",
    "s3_status = os.system('aws s3 ls s3://stpubdata --request-payer requester')\n",
    "\n",
    "# Move the figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "os.system('cp %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, 'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now have a list of the target names for the G102 and G141 observations in the ESA archive that overlap with the GS1 pointing of CLEAR. \n",
    "\n",
    "### For each target name, search the archive and retrieve all associated grism G102/G141 and direct imaging F098M/F105W/F125W/F140W observations.\n",
    "\n",
    "**For GS1, the retrieval step takes about 30 minutes to run and requires 1.9 GB of space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, targ_name in enumerate(overlapping_target_names):\n",
    "\n",
    "    if use_mquery:\n",
    "        extra = {'target_name':field}\n",
    "    else:\n",
    "        extra = query.DEFAULT_EXTRA.copy()\n",
    "        extra += [\"TARGET.TARGET_NAME LIKE '%s'\"%targ_name]\n",
    "\n",
    "    # search the ESA archive for overlapping grism and direct imaging observations with that target name\n",
    "    tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, filters=['G102', 'G141', 'F098M', 'F105W', 'F125W', 'F140W'], \n",
    "                                  instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], extra=extra, close=False)\n",
    "    if False:\n",
    "        s3_status = os.system('aws s3 ls s3://stpubdata --request-payer requester')\n",
    "\n",
    "        #retrieve the raw data products\n",
    "        auto_script.fetch_files(field_root=jtargname, HOME_PATH=HOME_PATH, remove_bad=True, \n",
    "                                reprocess_parallel=True, s3_sync=(s3_status == 0))\n",
    "\n",
    "    # Move the figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "    os.system('mv %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "\n",
    "    os.chdir(HOME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_RAW and PATH_TO_PREP are created in the previous steps\n",
    "PATH_TO_RAW     = glob(HOME_PATH + '/*/RAW')[0]\n",
    "PATH_TO_PREP    = glob(HOME_PATH + '/*/PREP')[0]\n",
    "\n",
    "\n",
    "class Pointing():\n",
    "    \"\"\" Generalization of GN1, GS1, ERSPRIME, etc\n",
    "\n",
    "    To change field-dependent catalog, seg map, ref image, and padding\n",
    "    only need to change them here.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, field, ref_filter):\n",
    "        if 'N' in field.upper():\n",
    "            self.pad = 500\n",
    "            self.radec_catalog = PATH_TO_CATS + '/old_radeccats/goodsN_radec.cat'\n",
    "            self.seg_map =  PATH_TO_CATS + '/Goods_N_plus_seg.fits'\n",
    "            self.catalog =  PATH_TO_CATS + '/goodsn-F105W-astrodrizzle-v4.4_drz_sub_plus.cat'\n",
    "            self.ref_image =  PATH_TO_CATS + '/goodsn-F105W-astrodrizzle-v4.4_drz_sci.fits'\n",
    "            \n",
    "            self.tempfilt, self.coeffs, self.temp_sed, self.pz = readEazyBinary(MAIN_OUTPUT_FILE='goodsn_3dhst.v4.1', OUTPUT_DIRECTORY=PATH_TO_CATS, CACHE_FILE='Same')\n",
    "            self.params = {}\n",
    "            self.params['CATALOG_FILE'] = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Catalog/{0}_3dhst.{1}.cat'.format('goodsn', 'v4.1')\n",
    "            self.params['Z_STEP'] = 0.002\n",
    "            self.params['Z_MAX'] = 4\n",
    "            self.params['MAIN_OUTPUT_FILE'] = '{0}_3dhst.{1}.eazypy'.format('goodsn', 'v4.1')\n",
    "            self.params['PRIOR_FILTER'] = 205\n",
    "            self.params['MW_EBV'] = {'aegis':0.0066, 'cosmos':0.0148, 'goodss':0.0069, \n",
    "                                    'uds':0.0195, 'goodsn':0.0103}['goodsn']\n",
    "            self.params['TEMPLATES_FILE'] = 'templates/fsps_full/tweak_fsps_QSF_12_v3.param'\n",
    "            self.translate_file = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Eazy/{0}_3dhst.{1}.translate'.format('goodsn', 'v4.1')\n",
    "\n",
    "        elif 'S' in field.upper():\n",
    "            self.pad = 200 # grizli default\n",
    "            self.radec_catalog =  PATH_TO_CATS + '/old_radeccats/goodsS_radec.cat'\n",
    "            self.seg_map =  PATH_TO_CATS + '/Goods_S_plus_seg.fits'\n",
    "            self.catalog =  PATH_TO_CATS + '/goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat'\n",
    "            self.ref_image =  PATH_TO_CATS + '/goodss-F105W-astrodrizzle-v4.3_drz_sci.fits'\n",
    "\n",
    "\n",
    "            self.tempfilt, self.coeffs, self.temp_sed, self.pz = readEazyBinary(MAIN_OUTPUT_FILE='goodss_3dhst.v4.1', OUTPUT_DIRECTORY=PATH_TO_CATS, CACHE_FILE='Same')\n",
    "            self.params = {}\n",
    "            self.params['CATALOG_FILE'] = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Catalog/{0}_3dhst.{1}.cat'.format('goodss', 'v4.1')\n",
    "            self.params['Z_STEP'] = 0.002\n",
    "            self.params['Z_MAX'] = 4\n",
    "            self.params['MAIN_OUTPUT_FILE'] = '{0}_3dhst.{1}.eazypy'.format('goodss', 'v4.1')\n",
    "            self.params['PRIOR_FILTER'] = 205\n",
    "            self.params['MW_EBV'] = {'aegis':0.0066, 'cosmos':0.0148, 'goodss':0.0069, \n",
    "                                    'uds':0.0195, 'goodsn':0.0103}['goodss']\n",
    "            self.params['TEMPLATES_FILE'] = 'templates/fsps_full/tweak_fsps_QSF_12_v3.param'\n",
    "            self.translate_file = PATH_TO_CATS + '/{0}_3dhst.{1}.cats/Eazy/{0}_3dhst.{1}.translate'.format('goodss', 'v4.1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def readEazyBinary(MAIN_OUTPUT_FILE='photz', OUTPUT_DIRECTORY='./OUTPUT', CACHE_FILE='Same'):\n",
    "\n",
    "    \"\"\"\n",
    "    Author: Gabe Brammer\n",
    "    This function has been clipped from eazyPy.py in thethreedhst git respository\n",
    "    https://github.com/gbrammer/threedhst/tree/master/threedhst\n",
    "\n",
    "    tempfilt, coeffs, temp_sed, pz = readEazyBinary(MAIN_OUTPUT_FILE='photz', \\\n",
    "                                                OUTPUT_DIRECTORY='./OUTPUT', \\\n",
    "                                                CACHE_FILE = 'Same')\n",
    "\n",
    "    Read Eazy BINARY_OUTPUTS files into structure data.\n",
    "    \n",
    "    If the BINARY_OUTPUTS files are not in './OUTPUT', provide either a relative or absolute path\n",
    "    in the OUTPUT_DIRECTORY keyword.\n",
    "    \n",
    "    By default assumes that CACHE_FILE is MAIN_OUTPUT_FILE+'.tempfilt'.\n",
    "    Specify the full filename if otherwise. \n",
    "    \"\"\"\n",
    "    \n",
    "    #root='COSMOS/OUTPUT/cat3.4_default_lines_zp33sspNoU'\n",
    "    \n",
    "    root = OUTPUT_DIRECTORY+'/'+MAIN_OUTPUT_FILE\n",
    "    \n",
    "    ###### .tempfilt\n",
    "    if CACHE_FILE == 'Same':\n",
    "        CACHE_FILE = root+'.tempfilt'\n",
    "    \n",
    "    if os.path.exists(CACHE_FILE) is False:\n",
    "        print(('File, %s, not found.' %(CACHE_FILE)))\n",
    "        return -1,-1,-1,-1\n",
    "    \n",
    "    f = open(CACHE_FILE,'rb')\n",
    "    \n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=4)\n",
    "    NFILT=s[0]\n",
    "    NTEMP=s[1]\n",
    "    NZ=s[2]\n",
    "    NOBJ=s[3]\n",
    "    tempfilt = np.fromfile(file=f,dtype=np.double,count=NFILT*NTEMP*NZ).reshape((NZ,NTEMP,NFILT)).transpose()\n",
    "    lc = np.fromfile(file=f,dtype=np.double,count=NFILT)\n",
    "    zgrid = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    fnu = np.fromfile(file=f,dtype=np.double,count=NFILT*NOBJ).reshape((NOBJ,NFILT)).transpose()\n",
    "    efnu = np.fromfile(file=f,dtype=np.double,count=NFILT*NOBJ).reshape((NOBJ,NFILT)).transpose()\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    tempfilt  = {'NFILT':NFILT,'NTEMP':NTEMP,'NZ':NZ,'NOBJ':NOBJ,\\\n",
    "                 'tempfilt':tempfilt,'lc':lc,'zgrid':zgrid,'fnu':fnu,'efnu':efnu}\n",
    "    \n",
    "    ###### .coeff\n",
    "    f = open(root+'.coeff','rb')\n",
    "    \n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=4)\n",
    "    NFILT=s[0]\n",
    "    NTEMP=s[1]\n",
    "    NZ=s[2]\n",
    "    NOBJ=s[3]\n",
    "    coeffs = np.fromfile(file=f,dtype=np.double,count=NTEMP*NOBJ).reshape((NOBJ,NTEMP)).transpose()\n",
    "    izbest = np.fromfile(file=f,dtype=np.int32,count=NOBJ)\n",
    "    tnorm = np.fromfile(file=f,dtype=np.double,count=NTEMP)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    coeffs = {'NFILT':NFILT,'NTEMP':NTEMP,'NZ':NZ,'NOBJ':NOBJ,\\\n",
    "              'coeffs':coeffs,'izbest':izbest,'tnorm':tnorm}\n",
    "              \n",
    "    ###### .temp_sed\n",
    "    f = open(root+'.temp_sed','rb')\n",
    "    s = np.fromfile(file=f,dtype=np.int32, count=3)\n",
    "    NTEMP=s[0]\n",
    "    NTEMPL=s[1]\n",
    "    NZ=s[2]\n",
    "    templam = np.fromfile(file=f,dtype=np.double,count=NTEMPL)\n",
    "    temp_seds = np.fromfile(file=f,dtype=np.double,count=NTEMPL*NTEMP).reshape((NTEMP,NTEMPL)).transpose()\n",
    "    da = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    db = np.fromfile(file=f,dtype=np.double,count=NZ)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    temp_sed = {'NTEMP':NTEMP,'NTEMPL':NTEMPL,'NZ':NZ,\\\n",
    "              'templam':templam,'temp_seds':temp_seds,'da':da,'db':db}\n",
    "              \n",
    "    ###### .pz\n",
    "    if os.path.exists(root+'.pz'):\n",
    "        f = open(root+'.pz','rb')\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=2)\n",
    "        NZ=s[0]\n",
    "        NOBJ=s[1]\n",
    "        chi2fit = np.fromfile(file=f,dtype=np.double,count=NZ*NOBJ).reshape((NOBJ,NZ)).transpose()\n",
    "\n",
    "        ### This will break if APPLY_PRIOR No\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=1)\n",
    "        \n",
    "        if len(s) > 0:\n",
    "            NK = s[0]\n",
    "            kbins = np.fromfile(file=f,dtype=np.double,count=NK)\n",
    "            priorzk = np.fromfile(file=f, dtype=np.double, count=NZ*NK).reshape((NK,NZ)).transpose()\n",
    "            kidx = np.fromfile(file=f,dtype=np.int32,count=NOBJ)\n",
    "            pz = {'NZ':NZ,'NOBJ':NOBJ,'NK':NK, 'chi2fit':chi2fit, 'kbins':kbins, 'priorzk':priorzk,'kidx':kidx}\n",
    "        else:\n",
    "            pz = None\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    else:\n",
    "        pz = None\n",
    "    \n",
    "    if False:\n",
    "        f = open(root+'.zbin','rb')\n",
    "        s = np.fromfile(file=f,dtype=np.int32, count=1)\n",
    "        NOBJ=s[0]\n",
    "        z_a = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_p = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_m1 = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_m2 = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        z_peak = np.fromfile(file=f,dtype=np.double,count=NOBJ)\n",
    "        f.close()\n",
    "        \n",
    "    ###### Done.    \n",
    "    return tempfilt, coeffs, temp_sed, pz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_TO_PREP)\n",
    "files = glob('%s/*flt.fits'%PATH_TO_RAW)\n",
    "info = grizli.utils.get_flt_info(files)\n",
    "visits, filters = grizli.utils.parse_flt_files(info=info, uniquename=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    product_names = np.array([visit['product'] for visit in visits])\n",
    "    filter_names = np.array([visit['product'].split('-')[-1] for visit in visits])\n",
    "    basenames = np.array([visit['product'].split('.')[0]+'.0' for visit in visits])\n",
    "\n",
    "    for ref_grism, ref_filter in [('G102', 'F105W'), ('G141', 'F140W')]:\n",
    "        print(ref_grism, ref_filter)\n",
    "\n",
    "        for v, visit in enumerate(visits):\n",
    "            product = product_names[v]\n",
    "            basename = basenames[v]\n",
    "            filt1 = filter_names[v]\n",
    "            field_in_contest = basename.split('-')[0]\n",
    "            if (ref_filter.lower() == filt1.lower()):\n",
    "                #Found a direct image, now search for grism counterpart\n",
    "                grism_index= np.where((basenames == basename) & (filter_names == ref_grism.lower()))[0][0]\n",
    "                p = Pointing(field = field, ref_filter = ref_filter)\n",
    "                radec_catalog = p.radec_catalog\n",
    "                print (field_in_contest, visits[grism_index])\n",
    "                status = process_direct_grism_visit(direct = visit,\n",
    "                                                    grism = visits[grism_index],\n",
    "                                                    radec = radec_catalog, \n",
    "                                                    align_mag_limits = [14, 23])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tabs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
