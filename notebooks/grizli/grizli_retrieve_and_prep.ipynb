{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## This notebook shows how to use Grizli to\n",
    "\n",
    "Retrieve and reduce raw CLEAR G102/F105W and 3D-HST G141/F140W observations for a specific CLEAR pointing (GS1).\n",
    "        \n",
    "** more comments inbound\n",
    "\n",
    "These series of notebooks draw heavily from Gabe Brammer's existing grizli notebooks, which are available at https://github.com/gbrammer/grizli/tree/master/examples, but with specific focus for the CLEAR survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grizli\n",
    "\n",
    "try: \n",
    "    from mastquery import query, overlaps\n",
    "    use_mquery = True\n",
    "except: \n",
    "    from hsaquery import query, overlaps\n",
    "    use_mquery = False\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from grizli.pipeline import auto_script\n",
    "import glob\n",
    "from glob import glob\n",
    "import astropy\n",
    "from grizli.prep import process_direct_grism_visit\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The paths defined below need to be changed to your own directories.\n",
    "### the PATH_TO_CATS directory should include the following:\n",
    "        ###     reference mosaic image (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sci.fits)\n",
    "        ###     segmentation map       (e.g., Goods_S_plus_seg.fits)\n",
    "        ###     source catalog         (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat)\n",
    "        ###     radec_catalog          (e.g., goodsS_radec.cat)\n",
    "        ###     3DHST Eazy Catalogs    (e.g., goodss_3dhst.v4.1.cats/*)\n",
    "### these are all available on the team archive: https://archive.stsci.edu/pub/clear_team/INCOMING/for_hackday/\n",
    "### the HOME_PATH directory is where the raw data, reduced data, and grizli outputs will be stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field           = 'GS1'\n",
    "ref_filter      = 'F105W'\n",
    "\n",
    "HOME_PATH       = '/Users/rsimons/Desktop/clear/for_hackday/%s'%field\n",
    "PATH_TO_CATS    = '/Users/rsimons/Desktop/clear/Catalogs'\n",
    "\n",
    "if not os.path.isdir(HOME_PATH): os.system('mkdir %s'%HOME_PATH)\n",
    "if not os.path.isdir(HOME_PATH + '/query_results'): os.system('mkdir %s/query_results'%HOME_PATH)\n",
    "\n",
    "os.chdir(HOME_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an initial query for all raw G102 data in the ESA archive with a target name that includes the phrase 'GS1' and a proposal ID of 14227 (i.e., GS1 pointing of CLEAR). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = query.run_query(box = None, proposal_id = [14227], instruments=['WFC3/IR', 'ACS/WFC'], \n",
    "                         filters = ['G102'], target_name = 'GS1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, find all overlapping G102 and G141 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all overlapping G102 and G141 observations in the archive\n",
    "tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, \n",
    "                              filters=['G102', 'G141'], \n",
    "                              instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], close=False)\n",
    "\n",
    "footprint_fits_file = glob('*footprint.fits')[0]\n",
    "jtargname = footprint_fits_file.strip('_footprint.fits')\n",
    "\n",
    "fp_fits = fits.open(footprint_fits_file)\n",
    "\n",
    "overlapping_target_names = set(fp_fits[1].data['target'])\n",
    "s3_status = os.system('aws s3 ls s3://stpubdata --request-payer requester')\n",
    "\n",
    "# Move the figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "os.system('cp %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, 'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now have a list of the target names for the G102 and G141 observations in the ESA archive that overlap with the GS1 pointing of CLEAR. \n",
    "\n",
    "### For each target name, search the archive and retrieve all associated grism G102/G141 and direct imaging F098M/F105W/F125W/F140W observations.\n",
    "\n",
    "**For GS1, the retrieval step takes about 30 minutes to run and requires 1.9 GB of space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, targ_name in enumerate(overlapping_target_names):\n",
    "\n",
    "\n",
    "    if use_mquery:\n",
    "        extra = {'target_name':targ_name}\n",
    "    else:\n",
    "        extra = query.DEFAULT_EXTRA.copy()\n",
    "        extra += [\"TARGET.TARGET_NAME LIKE '%s'\"%targ_name]\n",
    "    \n",
    "    # search the ESA archive for overlapping grism and direct imaging observations with that target name\n",
    "    tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, \n",
    "                                  filters=['G102', 'G141', 'F098M', 'F105W', 'F125W', 'F140W'], \n",
    "                                  instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], \n",
    "                                  extra=extra, close=False)\n",
    "    if False:\n",
    "        s3_status = os.system('aws s3 ls s3://stpubdata --request-payer requester')\n",
    "\n",
    "        #retrieve the raw data products\n",
    "        auto_script.fetch_files(field_root=jtargname, HOME_PATH=HOME_PATH, remove_bad=True, \n",
    "                                reprocess_parallel=True, s3_sync=(s3_status == 0))\n",
    "\n",
    "    # Move the figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "    os.system('mv %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "\n",
    "    os.chdir(HOME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_RAW and PATH_TO_PREP are created in the previous steps\n",
    "PATH_TO_RAW     = glob(HOME_PATH + '/*/RAW')[0]\n",
    "PATH_TO_PREP    = glob(HOME_PATH + '/*/PREP')[0]\n",
    "\n",
    "os.chdir(PATH_TO_PREP)\n",
    "files = glob('%s/*flt.fits'%PATH_TO_RAW)\n",
    "info = grizli.utils.get_flt_info(files)\n",
    "visits, filters = grizli.utils.parse_flt_files(info=info, uniquename=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    product_names = np.array([visit['product'] for visit in visits])\n",
    "    filter_names = np.array([visit['product'].split('-')[-1] for visit in visits])\n",
    "    basenames = np.array([visit['product'].split('.')[0]+'.0' for visit in visits])\n",
    "\n",
    "    for ref_grism, ref_filter in [('G102', 'F105W'), ('G141', 'F140W')]:\n",
    "        print(ref_grism, ref_filter)\n",
    "\n",
    "        for v, visit in enumerate(visits):\n",
    "            product = product_names[v]\n",
    "            basename = basenames[v]\n",
    "            filt1 = filter_names[v]\n",
    "            field_in_contest = basename.split('-')[0]\n",
    "            if (ref_filter.lower() == filt1.lower()):\n",
    "                #Found a direct image, now search for grism counterpart\n",
    "                grism_index= np.where((basenames == basename) & (filter_names == ref_grism.lower()))[0][0]\n",
    "                if 'N' in field.upper(): radec_catalog = PATH_TO_CATS + '/old_radeccats/goodsN_radec.cat'\n",
    "                if 'S' in field.upper(): radec_catalog = PATH_TO_CATS + '/old_radeccats/goodsS_radec.cat'                    \n",
    "                print (field_in_contest, visits[grism_index])\n",
    "                #status = process_direct_grism_visit(direct = visit,\n",
    "                #                                    grism = visits[grism_index],\n",
    "                #                                    radec = radec_catalog, \n",
    "                #                                    align_mag_limits = [14, 23])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
