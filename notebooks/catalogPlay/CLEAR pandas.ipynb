{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a notebook to read in the CLEAR and ancillary (3DHST) catalogs, select samples, and make some diagnostic plots\n",
    "\n",
    "This uses pandas to store the catalogs as DataFrames.  You need to use the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "\n",
    "from IPython.display import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories and test that they exist:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleardir = os.environ['HOME']+'/Data/CLEAR' # sets path to be $HOME/Data/CLEAR\n",
    "# sets path to be $HOME/Data/CLEAR\n",
    "# cleardir should include (available from the website): \n",
    "#    RELEASE_v1.0.0/\n",
    "#    RELEASE_v1.0.0/CATALOGS/\n",
    "# available from:  https://archive.stsci.edu/pub/clear_team/\n",
    "\n",
    "threeddir = os.environ['HOME']+'/Data/3DHST/photometry'\n",
    "\n",
    "# should include \n",
    "#    goodsn_3dhst.v4.1.cats/\n",
    "#.      Catalog/                \n",
    "#.      Eazy/ \n",
    "#       Fast/\n",
    "#.      RF_colors/\n",
    "#    goodss_3dhst.v4.1.cats/\n",
    "#.      Catalog/                \n",
    "#.      Eazy/ \n",
    "#       Fast/\n",
    "#.      RF_colors/\n",
    "# available from:  https://3dhst.research.yale.edu/Data.php\n",
    "\n",
    "\n",
    "catdir = os.path.join(cleardir,'CATALOGS') \n",
    "# sets path for $HOME/Data/CLEAR/CATALOGS\n",
    "# should include all files from CATALOGS/ directory at: \n",
    "#     https://archive.stsci.edu/pub/clear_team/CATALOGS/\n",
    "#    \n",
    "\n",
    "linedir = os.path.join(cleardir,'RELEASE_v1.0.0/CATALOGS')\n",
    "# should include all files from RELEASE_v1.0.0/CATALOGS/ directory at:\n",
    "#.    https://archive.stsci.edu/pub/clear_team/RELEASE_v1.0.0/CATALOGS/\n",
    "\n",
    "combineddir = os.path.join(cleardir,'RELEASE_v1.0.0/COMBINED')\n",
    "# shoudl include all files from https://archive.stsci.edu/pub/clear_team/RELEASE_v1.0.0/\n",
    "# download the tar.gz files and untar them - I sent a .sh script that has suggested ways to download everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOAD DATA from CLEAR archive site.\n",
    "\n",
    "If you need to do this, for look for AAA_wget.sh as an example of how you can auto download everything from the CLEAR site. It looks like this:\n",
    "```\n",
    "$ more AAA_wget.sh\n",
    "\n",
    "# this was a useful wget command to get all files\n",
    "\n",
    "# Run these from a ~/Data/CLEAR/ directory (that's what Casey did): (you might need to \"mkdir INCOMING\" and the other directories first)\n",
    "\n",
    "cd INCOMING && wget -r -nH --cut-dirs=4 --user='papovich@tamu.edu' --ask-password ftp://archive.stsci.edu//pub/clear_team/INCOMING/GoodsN_plus && cd ..\n",
    "\n",
    "cd INCOMING && wget -r -nH --cut-dirs=4 --user='papovich@tamu.edu' --ask-password ftp://archive.stsci.edu//pub/clear_team/INCOMING/GoodsS_plus && cd ..\n",
    "\n",
    "# FLT -- this will get everything... all 3.3 Gb worth or something\n",
    "\n",
    "cd FLTS && wget -r -nH --cut-dirs=4 --user='papovich@tamu.edu' --ask-password ftp://archive.stsci.edu//pub/clear_team/FLTS/*.fits && cd ..\n",
    "\n",
    "# (Might need to \"mkdir RELEASE_v1.0.0\" first... )\n",
    "\n",
    "cd RELEASE_v1.0.0 && wget -r -nH --cut-dirs=4 --user='papovich@tamu.edu' --ask-password ftp://archive.stsci.edu//pub/clear_team/RELEASE_v1.0.0/* && cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check that all the directories we just set up do exist:\n",
    "\n",
    "for d in [cleardir, catdir, linedir, threeddir,combineddir] :\n",
    "    if os.path.exists(d) : print (\"EXISTS: %s\" % d)\n",
    "    else : print(\"DOES NOT EXIST: %s\" %  d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if all GOODS-North catalogs are in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gndfile = os.path.join(catdir,'goodsn_3dhst.v4.3.cat')\n",
    "gndzoutfile = os.path.join(catdir,'goodsn_v4.3.zout')\n",
    "gndlinefile = os.path.join(linedir,'GN_CLEAR.linefit.concat.v1.0.0.fits')\n",
    "gndzfitfile = os.path.join(linedir,'GN_CLEAR.zfit.concat.v1.0.0.fits')\n",
    "gndfoutfile = os.path.join(catdir,'goodsn_v4.3.fout')\n",
    "#gndfoutfile = os.path.join(threeddir,'goodsn_3dhst.v4.1.cats','Fast','goodsn_3dhst.v4.1.fout')\n",
    "\n",
    "# all need to exist:\n",
    "for file in [gndfile, gndzoutfile, gndlinefile, gndzfitfile,gndfoutfile] : \n",
    "    if os.path.exists(file) : print (\"EXISTS: %s\" % file)\n",
    "    else: print(\"DOES NOT EXIST: %s\" %  d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if all GOODS-South catalogs are in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsdfile = os.path.join(catdir,'goodss_3dhst.v4.3.cat')\n",
    "gsdzoutfile = os.path.join(catdir,'goodss_v4.3.zout')\n",
    "gsdlinefile = os.path.join(linedir,'GS_CLEAR.linefit.concat.v1.0.0.fits')\n",
    "gsdzfitfile = os.path.join(linedir,'GS_CLEAR.zfit.concat.v1.0.0.fits')\n",
    "gsdfoutfile = os.path.join(catdir,'goodss_v4.3.fout')\n",
    "#gsdfoutfile = os.path.join(threeddir,'goodss_3dhst.v4.1.cats/','Fast','goodss_3dhst.v4.1.fout')\n",
    "\n",
    "for file in [gndfile, gndzoutfile, gndlinefile, gndzfitfile,gndfoutfile] : \n",
    "    if os.path.exists(file) : print (\"EXISTS: %s\" % file)\n",
    "    else: print(\"DOES NOT EXIST: %s\" %  d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The COMBINED Directory is expected to look like this: \n",
    "```\n",
    "COMBINED/\n",
    "    \n",
    "1D/FITS\n",
    "1D/PNG\n",
    "2D/FITS\n",
    "2D/PNG\n",
    "LINEFIT/CHAIN_PNG\n",
    "LINEFIT/DAT\n",
    "LINEFIT/FITS\n",
    "LINEFIT/PNG\n",
    "ZFIT/2D_FITS\n",
    "ZFIT/2D_PNG\n",
    "ZFIT/DAT\n",
    "ZFIT/FITS\n",
    "ZFIT/PNG\n",
    "ZFIT/PZ_FITS\n",
    "ZFIT/TILT_DAT\n",
    "ZFIT/TILT_PNG\n",
    "```\n",
    "The commands in the next In [] block should produce the output above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The COMBINED Directory is expected to look like this: \n",
    "#for d in os.listdir(combineddir) : \n",
    "for dls in os.listdir(combineddir) : \n",
    "    if dls != \".DS_Store\" : \n",
    "        for d in os.listdir(os.path.join(combineddir,dls)) : \n",
    "            if d != \".DS_Store\" : \n",
    "                print(os.path.join(dls,d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Next, read all the catalogs into PANDAS data frames\n",
    "This is set up to read the ascii files. You can read them from FITS using astropy Table and pandas (that's probably easier in some ways): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a routine to read in all the catalogs: \n",
    "def loadclear( catfile, zoutfile, foutfile, zfitfile, linefile, doprint=False) : \n",
    "\n",
    "    cat = Table.read(catfile, format='ascii').to_pandas()\n",
    "    zcat = Table.read(zoutfile, format='ascii').to_pandas()\n",
    "    fcat = Table.read(foutfile, format='ascii').to_pandas()\n",
    "    \n",
    "    zfitcat = Table.read(zfitfile).to_pandas()\n",
    "    linecat = Table.read(linefile).to_pandas()\n",
    "    \n",
    "    return(cat, zcat, fcat, zfitcat, linecat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all the catalogs. This may take a few seconds, we are opening all 10 files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd, gndz, gndf, gndzfit, gndline = loadclear(gndfile, gndzoutfile, gndfoutfile, \n",
    "                                              gndzfitfile, gndlinefile)\n",
    "gsd, gsdz, gsdf, gsdzfit, gsdline = loadclear(gsdfile, gsdzoutfile, gsdfoutfile, \n",
    "                                              gsdzfitfile, gsdlinefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we now have\n",
    "\n",
    "__gnd__:  CLEAR photometric catalog for GOODS-N Deep.  This is ID matched to 3DHST, but includes the HST WFC3 Y-band photometry.\n",
    "\n",
    "__gndz__:  CLEAR EAZY file (z-phot) based on the broad-band photometry.\n",
    "\n",
    "__gndf__:  CLEAR FOUT file (from EAZY) - has mass information, but something is odd with it... \n",
    "\n",
    "__gndzfit__:  CLEAR G102 grism redshift fits from Iva, __NOT LINEMATCHED__\n",
    "\n",
    "__gndlinefit__:  CLEAR G102 grism emission line identification using the zfit's, __NOT LINEMATCHED__\n",
    "\n",
    "Similar files for gsd for GOODS-S Deep.\n",
    "\n",
    "Below you can display some of these: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# limit display to 10 rows:\n",
    "pd.options.display.max_rows=10\n",
    "\n",
    "# select only objects with \"use==1\" and display them to see some of their properties:\n",
    "# scroll down to see all tables and to the right to see all columns\n",
    "# Note: they all have the same number of rows!\n",
    "ok = (gnd['use']==1)\n",
    "display(gnd[ok],gndz[ok],gndf[ok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the concatenated z_grism and emission line tables:\n",
    "# Note: these are much shorter\n",
    "display(gndzfit,gndline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find an object with really high [OIII] flux and display some info and Images: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok = (np.where((gndline['Hb_EQW'] > 10) & (gndline['OIII_EQW'] > 40)))[0]\n",
    "tok = (gndline['Hb_EQW'] > 10) & (gndline['OIII_EQW'] > 40) & (gndline['Hb_EQW']/gndline['Hb_EQW_ERR'] > 3) & (gndline['OIII_EQW']/gndline['OIII_EQW_ERR'] > 3)\n",
    "print(\"There are %d objects which fit these criteria\" % (np.sum(tok)))\n",
    "pd.options.display.max_rows=9999\n",
    "display(gndline.loc[tok])\n",
    "pd.options.display.max_rows=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine files for a single object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, take the fourth entry above (line 39 in the full catalog), PHOT_ID=33115 in GND, print it's information and display the files associated with it:\n",
    "\n",
    "If you want to see a bad emission line, change these to the object is line 31 (PHOT_ID = 32632)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gndzfit['phot_id'][39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SearchID = 33115\n",
    "\n",
    "ok = (np.where(gndzfit['phot_id'] == SearchID))\n",
    "pd.options.display.max_rows=9999\n",
    "display(gndzfit.loc[ok], gndline.loc[ok])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find what files are available for this object in the directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the subdirectories available under the 'combineddir'\n",
    "os.listdir(combineddir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 14 files for the combined spectrum of this object and out of the :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### I will search all GN* directories for files associated with this object:\n",
    "files_all = glob('%s/*/*/*%s*' % (combineddir, SearchID))\n",
    "\n",
    "\n",
    "print('There are a total of %d files for the combined spectrum of this object.' % (len(files_all)))\n",
    "\n",
    "### Uncommend the lines below if you want to list the files\n",
    "#for file in files:\n",
    "#    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this object is only found in the GN3 field.\n",
    "\n",
    "There are several PNG files which are meant to be for diagnostic purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_png = glob('%s/*/*/*%s*.png' % (combineddir, SearchID))\n",
    "print('Found %d PNG files.' % len(files_png))\n",
    "for file in files_png:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first file in this list, the __GN3-G102_32632_stack.png__ file, shows all the individual spectra that went into the stack. Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(files_png[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a row for each spectrum in the final stack with the bottom-most spectrum showing the final co-add. The left column shows the observed spectra, the middle one is the calculated contamination, the right one if flux minus contamination. The top two spectra (from pointings GDN18 and GDN22) are from the Barro GO program. The lines clearly show in all PAs which indicates that they are real lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change 4 to 1,2,3,5 to see the other diagnostic plots\n",
    "Image(files_png[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the (1) grism spectrum counts/s vs. lambda (2) same converted to flux vs lambda (3) p(z) vs z and (4) best fit SED, photometric points, spectrum.\n",
    "\n",
    "The lines Hb and OIII are clearly visible. The p(z) matches the ground-based spec_z really well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some of the FITS files and see where the data for these plots came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_fits = glob('%s/*/*/*%s*.fits' % (combineddir, SearchID))\n",
    "print('Found %d FITS files.' % len(files_fits))\n",
    "for file in files_fits:\n",
    "    file = file.split('/')[-1]\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### This is the content of the 2D file, this is the file which contains the stack:\n",
    "print(files_fits[1])\n",
    "twod_spec = fits.open(files_fits[1])\n",
    "twod_spec.info()\n",
    "twod_spec[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0th extension is header whith some information about the spectrum. View is with ```foo[0].header```. All the spectra which went into the stack are in the ```TWOD``` keywords in this header.\n",
    "\n",
    "Extensions 1,2,3 and 4 are postage stams from the science direct image, interlaced image, weight map and segmentation map respectively (hint: they are sqare so clearly not spectra, see the dimentions in the 4th column).\n",
    "\n",
    "Extensions 5,6,7 and 8 are spectral 2D arrays containing the spectrum (INCLUDING CONTAMINATION), the error array, the model (of the spectrum itself) and the contramination model (of everything else) respectively.\n",
    "\n",
    "Extension 9, 10 and 11 are 1D arrays containing the wavelength solution, the sensitivity and the trace (in y) at each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(twod_spec[1].data)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(twod_spec[2].data)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(twod_spec[3].data)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(twod_spec[4].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.imshow(twod_spec[5].data, vmin=0.0, vmax=0.01)\n",
    "\n",
    "plt.subplot(5, 1, 2)\n",
    "plt.imshow(twod_spec[5].data-twod_spec[8].data, vmin=0.0, vmax=0.01)\n",
    "\n",
    "plt.subplot(5, 1, 3)\n",
    "plt.imshow(twod_spec[6].data, vmin=0.0, vmax=0.01)\n",
    "\n",
    "plt.subplot(5, 1, 4)\n",
    "plt.imshow(twod_spec[7].data, vmin=0.0, vmax=0.01)\n",
    "\n",
    "plt.subplot(5, 1, 5)\n",
    "plt.imshow(twod_spec[8].data, vmin=0.0, vmax=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# Now, restrict objects to only those in CLEAR and do several things.\n",
    "Here we make a pandas data frame, matching by ID numbers only those objects in the CLEAR ZFIT and LINE catalogs: \n",
    "\n",
    "We will use the pandas (pd) merge routine (pd.merge()).  (You can also use pd.concat, but that matches line-by-line.). There are other routines to match by RA and Dec. \n",
    "\n",
    "When the routine below is done, we have one dataframe with *all* the information from the other dataframes in it, but only for objects that appear in the CLEAR zfit and linefit catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# could use pd.concat, but this matches line-by-line\n",
    "# gsddf = pd.concat([gsd,gsdz],axis=1) \n",
    "#gsddf = pd.concat([gsddf,gsdf],axis=1)\n",
    "# default is join='outer', which pads cells with NaNs (that's what you want)  \n",
    "# join='inner' only keeps rows that are in both catalogs. \n",
    "# the axis=1 means to match by ID number\n",
    "#\n",
    "# The only caveat is if columns in the different dataframes have the same column name - not sure what happens then.\n",
    "#display(gnddf)\n",
    "\n",
    "# INSTEAD:  here we use PANDAS MERGE routine to match based on keys (on=\"key\") that are the name of the columns.\n",
    "\n",
    "def domerge(gnd, gndz, gndf, gndzfit, gndlinefit) : \n",
    "    # add 'id' to zfit and linefit so we can key off those. \n",
    "    # could also use .merge(left, right, left_on='phot_id', right_on='id').... \n",
    "    gndzfit['id'] = gndzfit['phot_id']\n",
    "    gndlinefit['id'] = gndlinefit['phot_id']\n",
    "    # \n",
    "    \n",
    "    gnddf = gndzfit\n",
    "    print(\"Initial number of objects with grism zfits: %i\" % len(gnddf))\n",
    "\n",
    "\n",
    "    for f in [gnd, gndz, gndf, gndlinefit] : \n",
    "        gnddf = pd.merge(gnddf,f,on='id',how='inner')\n",
    "\n",
    "    print(\"Final number (includes objects with different line identifications: %i\" % len(gnddf))\n",
    "    print()\n",
    "    return(gnddf)\n",
    "\n",
    "print(\"The reason there are more objects in the final than initial is that about ~100 objects fall in regions of overlap between CLEAR fields\\n \")\n",
    "gnddf = domerge(gnd,gndz,gndf, gndzfit, gndline)\n",
    "gsddf = domerge(gsd,gsdz,gsdf, gsdzfit, gsdline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates: \n",
    "\n",
    "One thing we can do is look for objects with duplicated ID numbers - these are objects that have coverage in 2 CLEAR pointings (e.g., they fall in GN3 and GN5) and so have two entries.  We can look at those: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the Duplicates - \n",
    "# this only finds objects that have the same \"phot_id\" and lists them:\n",
    "ok = gnddf['id'].duplicated()\n",
    "#pd.options.display.max_columns = 10\n",
    "display(gnddf[ok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at object 34077\n",
    "ok=np.where((gnddf['phot_id_x']==34077))[0]\n",
    "display(gnddf.iloc[ok])\n",
    "#ok\n",
    "#display(gndline[ok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sname = [gnddf['grism_id_x'][ok[i]].decode('ASCII') for i in range(len(ok))] \n",
    "sname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1, figsize=(50,25))\n",
    "#for s, i, j in zip(sname,[0,1,0,1], [0,0,1,1]) : \n",
    "for s, i in zip(sname[1:3], np.arange(0,2)) : \n",
    "    img=mpimg.imread('%s/2D/PNG/%s_stack.png' % (combineddir,s))\n",
    "    #img=mpimg.imread('%s/2D/PNG/%s_stack.png' % (combineddir, s))\n",
    "    axes[i].imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare z(grism) with z(phot) (latter is from broad-band fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows=2\n",
    "pd.options.display.max_columns=9999\n",
    "display(gnddf)\n",
    "pd.options.display.max_rows=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select \"usable\" objects: \n",
    "okn = ((gnddf.use == 1) & (gnddf.z_peak_grism > 0))\n",
    "oks = ((gsddf.use == 1) & (gsddf.z_peak_grism > 0))\n",
    "print(len(okn),len(oks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot z(phot) against z(grism)\n",
    "#mpl.rc('xtick', labelsize=20) \n",
    "#mpl.rc('ytick', labelsize=20) \n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,15))\n",
    "axes[0].scatter( gnddf['z_peak_phot'][okn], gnddf['z_peak_grism'][okn])\n",
    "axes[1].scatter( gsddf['z_peak_phot'][oks], gsddf['z_peak_grism'][oks])\n",
    "for ax, label in zip(axes,['GND','GSD']) : \n",
    "    ax.set_xlabel('z(phot)')\n",
    "    ax.set_ylabel('z(grism)')\n",
    "    ax.set_xlim([0,5])\n",
    "    ax.set_ylim([0,5])\n",
    "    ax.plot([0,5],[0,5],'-r')\n",
    "    ax.text(0.5,4.5,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, read in 3DHST FAST catalogs, match to our objects, and plot H-alpha EW vs. stellar mass: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gndfastfile = os.path.join(threeddir,\n",
    "                           'goodsn_3dhst.v4.1.cats','Fast',\n",
    "                           'goodsn_3dhst.v4.1.fout')\n",
    "gsdfastfile = os.path.join(threeddir,\n",
    "                           'goodss_3dhst.v4.1.cats','Fast',\n",
    "                           'goodss_3dhst.v4.1.fout')\n",
    "def readfast(fastfile,doprint=True) : \n",
    "    #fcolnames = getcol(fastfile, doprint=doprint)\n",
    "    fcat = Table.read(fastfile, format='ascii').to_pandas()\n",
    "    #fcat = pd.read_table(fastfile,comment='#', \n",
    "    #                     delim_whitespace=True, names=fcolnames)\n",
    "    return(fcat)\n",
    "\n",
    "gndfast = readfast(gndfastfile)\n",
    "gsdfast = readfast(gsdfastfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the CLEAR grism line catalogs with the 3DHST FAST catalogs based on ID number\n",
    "gndEW = pd.merge(gndline,gndfast,on='id',how='inner')\n",
    "gsdEW = pd.merge(gsdline,gndfast, on='id', how='inner')\n",
    "pd.options.display.max_rows=2\n",
    "display(gndEW)\n",
    "pd.options.display.max_rows=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin = (8500./6563. - 1)\n",
    "zmax = (12500./6563. - 1)\n",
    "okn = ((gndEW.Ha_EQW > 1) & (gndEW.z_max_grism > zmin) & \n",
    "                            (gndEW.z_max_grism < zmax))\n",
    "oks = ((gsdEW.Ha_EQW > 1) & (gsdEW.z_max_grism > zmin) & \n",
    "                            (gsdEW.z_max_grism < zmax))\n",
    "print(\"# of GND galaxies with Ha and %4.2f < z < %4.2f = %i\" %\n",
    "      (zmin, zmax, len((np.where(okn==True))[0])))\n",
    "print(\"# of GSD galaxies with Ha and %4.2f < z < %4.2f = %i\" %\n",
    "      (zmin, zmax, len((np.where(oks==True))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,15))\n",
    "axes[0].scatter( gndEW['lmass'][okn], gndEW['Ha_EQW'][okn])\n",
    "axes[1].scatter( gsdEW['lmass'][oks], gsdEW['Ha_EQW'][oks])\n",
    "\n",
    "#axes[1].scatter( gsddf['z_peak_phot'][oks], gsddf['z_peak_grism'][oks])\n",
    "for ax, label in zip(axes,['GND','GSD']) : \n",
    "    ax.set_xlabel('log Mass')\n",
    "    ax.set_ylabel(r'EW(H$\\alpha$)')\n",
    "    ax.set_ylim([1,1000])\n",
    "    ax.set_yscale(\"log\", nonposy='clip')\n",
    "    ax.set_xlim([8,11.5])\n",
    "#    #ax.plot([0,5],[0,5],'-r')\n",
    "    ax.text(11,500,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
